diff --git a/Changes b/Changes
index 45f97509eef6..023ae9a70431 100644
--- a/Changes
+++ b/Changes
@@ -200,6 +200,9 @@ Working version
   style that the compiler driver uses.
   (David Allsopp, review by Gabriel Scherer)
 
+- #12810: Port ThreadSanitizer support to Linux and macOS on arm64
+  (Miod Vallat, review by Tim McGilchrist)
+
 ### Code generation and optimizations:
 
 - #11239: on x86-64 and RISC-V, reduce alignment of OCaml stacks from 16 to 8.
diff --git a/configure b/configure
index d08d903f9ab2..4dba342ac136 100755
--- a/configure
+++ b/configure
@@ -16637,7 +16637,8 @@ esac
 
 fi
 
-# ThreadSanitizer support is only for Linux/FreeBSD/macOS on amd64.
+# ThreadSanitizer support is only for Linux/FreeBSD/macOS on amd64, as well as
+# Linux/macOS on arm64.
 # ThreadSanitizer supports more architectures but the OCaml client side is not
 # implemented (yet).
 if test "x$enable_tsan" = "xyes"
@@ -16654,7 +16655,22 @@ then :
           ;;
 esac ;; #(
   *) :
-     ;;
+    as_fn_error $? "thread sanitizer not supported on system $system" "$LINENO" 5
+        ;;
+esac ;; #(
+  arm64) :
+    case "$system" in #(
+  linux|macosx) :
+    case "$ocaml_cv_cc_vendor" in #(
+  gcc-*|clang-*) :
+    tsan=true ;; #(
+  *) :
+    as_fn_error $? "thread sanitizer not supported with vendor=$ocaml_cv_cc_vendor\"" "$LINENO" 5
+          ;;
+esac ;; #(
+  *) :
+    as_fn_error $? "thread sanitizer not supported on system $system" "$LINENO" 5
+        ;;
 esac ;; #(
   *) :
     as_fn_error $? "thread sanitizer not supported on arch $arch" "$LINENO" 5
@@ -16789,7 +16805,14 @@ fi
   "macosx") :
     libunwind_ldflags="-framework System" ;; #(
   *) :
-    libunwind_ldflags="-lunwind -lunwind-x86_64" ;;
+    case "$arch" in #(
+  "amd64") :
+    libunwind_ldflags="-lunwind -lunwind-x86_64" ;; #(
+  "arm64") :
+    libunwind_ldflags="-lunwind -lunwind-aarch64" ;; #(
+  *) :
+     ;;
+esac ;;
 esac
 
   if test x"$LIBUNWIND_LDFLAGS" != x
diff --git a/configure.ac b/configure.ac
index b17ee003e136..3e9c4020d06f 100644
--- a/configure.ac
+++ b/configure.ac
@@ -1665,7 +1665,8 @@ AS_IF([test "x$enable_instrumented_runtime" != "xno" ],
     )]
 )
 
-# ThreadSanitizer support is only for Linux/FreeBSD/macOS on amd64.
+# ThreadSanitizer support is only for Linux/FreeBSD/macOS on amd64, as well as
+# Linux/macOS on arm64.
 # ThreadSanitizer supports more architectures but the OCaml client side is not
 # implemented (yet).
 AS_IF([test "x$enable_tsan" = "xyes" ],
@@ -1678,6 +1679,17 @@ AS_IF([test "x$enable_tsan" = "xyes" ],
           [AC_MSG_ERROR(m4_normalize([thread sanitizer not supported with
             vendor=$ocaml_cv_cc_vendor"]))]
          )],
+        [AC_MSG_ERROR([thread sanitizer not supported on system $system])]
+       )],
+    [arm64],
+      [AS_CASE(["$system"],
+        [linux|macosx],
+        [AS_CASE(["$ocaml_cv_cc_vendor"],
+          [gcc-*|clang-*], [tsan=true],
+          [AC_MSG_ERROR(m4_normalize([thread sanitizer not supported with
+            vendor=$ocaml_cv_cc_vendor"]))]
+         )],
+        [AC_MSG_ERROR([thread sanitizer not supported on system $system])]
        )],
       [AC_MSG_ERROR([thread sanitizer not supported on arch $arch])]
   )],
@@ -1740,7 +1752,9 @@ AS_IF([$tsan],
   AS_CASE(["$system"],
     ["freebsd"], [libunwind_ldflags="-lgcc_eh"],
     ["macosx"], [libunwind_ldflags="-framework System"],
-    [libunwind_ldflags="-lunwind -lunwind-x86_64"])
+    [AS_CASE(["$arch"],
+      ["amd64"], [libunwind_ldflags="-lunwind -lunwind-x86_64"],
+      ["arm64"], [libunwind_ldflags="-lunwind -lunwind-aarch64"])])
 
   AS_IF([test x"$LIBUNWIND_LDFLAGS" != x],
     [libunwind_ldflags="$LIBUNWIND_LDFLAGS $libunwind_ldflags"])
diff --git a/manual/src/cmds/tsan.etex b/manual/src/cmds/tsan.etex
index 16cc3ebe220b..f00873a46c88 100644
--- a/manual/src/cmds/tsan.etex
+++ b/manual/src/cmds/tsan.etex
@@ -26,7 +26,8 @@ opam switch create <YOUR-SWITCH-NAME-HERE> ocaml-option-tsan
 \end{verbatim}
 
 TSan support for OCaml is currently available for the x86_64 architecture, on
-GNU/Linux and macOS systems. Building OCaml with TSan support requires GCC or
+FreeBSD, Linux and macOS, and for the arm64 architecture on Linux and macOS.
+Building OCaml with TSan support requires GCC or
 Clang. Minimal supported versions are GCC 11 and Clang 14. Note that TSan data
 race reports with GCC 11 are known to result in poor stack trace reporting (no
 line numbers), which is fixed in GCC 12.
diff --git a/runtime/arm64.S b/runtime/arm64.S
index 538688ce05a2..423637e738ac 100644
--- a/runtime/arm64.S
+++ b/runtime/arm64.S
@@ -319,6 +319,130 @@ G(name):
         ldr     TRAP_PTR, Caml_state(exn_handler)
 .endm
 
+#if defined(WITH_THREAD_SANITIZER) /* { */
+
+/* Push the current value of the link register to the stack. */
+.macro TSAN_SETUP_C_CALL
+        CFI_OFFSET(30, -16)
+        str     x30, [sp, -16]!
+        CFI_ADJUST(16)
+.endm
+
+/* Restore the value of the link register from the stack. */
+.macro TSAN_CLEANUP_AFTER_C_CALL
+        ldr     x30, [sp], 16
+        CFI_ADJUST(-16)
+.endm
+
+/* Invoke a C function, switching back and forth the OCaml and C stacks. */
+.macro TSAN_C_CALL fun
+        SWITCH_OCAML_TO_C
+        TSAN_SETUP_C_CALL
+        bl      \fun
+        TSAN_CLEANUP_AFTER_C_CALL
+        SWITCH_C_TO_OCAML
+.endm
+
+/* Invoke __tsan_func_entry(return address in the caller) */
+.macro TSAN_ENTER_FUNCTION
+        mov     x0, x30        /* arg1: return address in caller */
+        TSAN_C_CALL G(__tsan_func_entry)
+.endm
+
+/* Invoke __tsan_func_exit(0) */
+.macro TSAN_EXIT_FUNCTION
+        mov     x0, xzr
+        TSAN_C_CALL G(__tsan_func_exit)
+.endm
+
+/* This is similar to SAVE_ALL_REGS, but only saving the caller-saved
+   registers. */
+.macro TSAN_SAVE_CALLER_REGS
+    /* First, save the young_ptr & exn_handler */
+        str     ALLOC_PTR, Caml_state(young_ptr)
+        str     TRAP_PTR, Caml_state(exn_handler)
+    /* Now, use TMP to point to the gc_regs bucket */
+        ldr     TMP, Caml_state(gc_regs_buckets)
+        ldr     TMP2, [TMP, 0] /* next ptr */
+        str     TMP2, Caml_state(gc_regs_buckets)
+    /* Save caller-saved registers */
+        stp     x0, x1, [TMP, 16]
+        stp     x2, x3, [TMP, 32]
+        stp     x4, x5, [TMP, 48]
+        stp     x6, x7, [TMP, 64]
+        stp     x8, x9, [TMP, 80]
+        stp     x10, x11, [TMP, 96]
+        stp     x12, x13, [TMP, 112]
+        stp     x14, x15, [TMP, 128]
+    /* Save caller-save floating-point registers */
+        stp     d0, d1, [TMP, 208]
+        stp     d2, d3, [TMP, 224]
+        stp     d4, d5, [TMP, 240]
+        stp     d6, d7, [TMP, 256]
+        stp     d16, d17, [TMP, 272]
+        stp     d18, d19, [TMP, 288]
+        stp     d20, d21, [TMP, 304]
+        stp     d22, d23, [TMP, 320]
+        stp     d24, d25, [TMP, 336]
+        stp     d26, d27, [TMP, 352]
+        stp     d28, d29, [TMP, 368]
+        stp     d30, d31, [TMP, 384]
+        add     TMP, TMP, #16
+        str     TMP, Caml_state(gc_regs)
+.endm
+
+/* This is similar to RESTORE_ALL_REGS, but only restoring the caller-saved
+   registers. */
+.macro TSAN_RESTORE_CALLER_REGS
+    /* Restore x0, x1, freeing up the next ptr slot */
+        ldr     TMP, Caml_state(gc_regs)
+        sub     TMP, TMP, #16
+    /* Restore registers */
+        ldp     x0, x1, [TMP, 16]
+        ldp     x2, x3, [TMP, 32]
+        ldp     x4, x5, [TMP, 48]
+        ldp     x6, x7, [TMP, 64]
+        ldp     x8, x9, [TMP, 80]
+        ldp     x10, x11, [TMP, 96]
+        ldp     x12, x13, [TMP, 112]
+        ldp     x14, x15, [TMP, 128]
+        ldp     d0, d1, [TMP, 208]
+        ldp     d2, d3, [TMP, 224]
+        ldp     d4, d5, [TMP, 240]
+        ldp     d6, d7, [TMP, 256]
+        ldp     d16, d17, [TMP, 272]
+        ldp     d18, d19, [TMP, 288]
+        ldp     d20, d21, [TMP, 304]
+        ldp     d22, d23, [TMP, 320]
+        ldp     d24, d25, [TMP, 336]
+        ldp     d26, d27, [TMP, 352]
+        ldp     d28, d29, [TMP, 368]
+        ldp     d30, d31, [TMP, 384]
+    /* Put gc_regs struct back in bucket linked list */
+        ldr     TMP2, Caml_state(gc_regs_buckets)
+        str     TMP2, [TMP, 0]  /* next ptr */
+        str     TMP, Caml_state(gc_regs_buckets)
+    /* Reload new allocation pointer & exn handler */
+        ldr     ALLOC_PTR, Caml_state(young_ptr)
+        ldr     TRAP_PTR, Caml_state(exn_handler)
+.endm
+
+#else /* } { */
+
+.macro TSAN_ENTER_FUNCTION
+.endm
+
+.macro TSAN_EXIT_FUNCTION
+.endm
+
+.macro TSAN_SAVE_CALLER_REGS
+.endm
+
+.macro TSAN_RESTORE_CALLER_REGS
+.endm
+
+#endif /* } WITH_THREAD_SANITIZER */
+
 /* Allocation functions and GC interface */
         TEXT_SECTION(caml_system__code_begin)
         .globl  G(caml_system__code_begin)
@@ -433,6 +557,9 @@ FUNCTION(caml_c_call)
         stp     x29, x30, [sp, -16]!
         CFI_ADJUST(16)
         add     x29, sp, #0
+        TSAN_SAVE_CALLER_REGS
+        TSAN_ENTER_FUNCTION
+        TSAN_RESTORE_CALLER_REGS
     /* Switch from OCaml to C */
         SWITCH_OCAML_TO_C
     /* Make the exception handler alloc ptr available to the C code */
@@ -444,6 +571,21 @@ FUNCTION(caml_c_call)
         ldr     ALLOC_PTR, Caml_state(young_ptr)
     /* Load ocaml stack */
         SWITCH_C_TO_OCAML
+#if defined(WITH_THREAD_SANITIZER)
+    /* Save return value registers. Since the called function could be
+       anything, it may have returned its result (if any) either in x0
+       or d0:d1. */
+        stp     x0, x1, [sp, -16]!
+        CFI_ADJUST(16)
+        stp     d0, d1, [sp, -16]!
+        CFI_ADJUST(16)
+        TSAN_EXIT_FUNCTION
+    /* Restore return value registers */
+        ldp     d0, d1, [sp], 16
+        CFI_ADJUST(-16)
+        ldp     x0, x1, [sp], 16
+        CFI_ADJUST(-16)
+#endif
     /* Return */
         ldp     x29, x30, [sp], 16
         RET_FROM_C_CALL
@@ -495,6 +637,18 @@ END_FUNCTION(caml_c_call_stack_args)
 
 FUNCTION(caml_start_program)
         CFI_STARTPROC
+#if defined(WITH_THREAD_SANITIZER)
+        str     x0, [sp, -16]!
+        CFI_ADJUST(16)
+    /* We can't use the TSAN_ENTER_FUNCTION macro, as it assumes to run on an
+       OCaml stack, and we are still on a C stack at this point. */
+        mov     x0, x30        /* arg1: return address in caller */
+        TSAN_SETUP_C_CALL
+        bl      G(__tsan_func_entry)
+        TSAN_CLEANUP_AFTER_C_CALL
+        ldr     x0, [sp], 16
+        CFI_ADJUST(-16)
+#endif
     /* domain state is passed as arg from C */
         mov     TMP, C_ARG_1
         ADDRGLOBAL(TMP2, caml_program)
@@ -586,6 +740,18 @@ L(return_result):
         add     sp, sp, 32
         CFI_ADJUST(-32)
         str     x8, Caml_state(c_stack)
+#if defined(WITH_THREAD_SANITIZER)
+    /* We can't use the TSAN_EXIT_FUNCTION macro, as it assumes to run on an
+       OCaml stack, and we are back to a C stack at this point. */
+        str     x0, [sp, -16]!
+        CFI_ADJUST(16)
+        mov     x0, xzr
+        TSAN_SETUP_C_CALL
+        bl      G(__tsan_func_exit)
+        TSAN_CLEANUP_AFTER_C_CALL
+        ldr     x0, [sp], 16
+        CFI_ADJUST(-16)
+#endif
     /* Reload callee-save registers and return address */
         ldp     x19, x20, [sp, 16]
         ldp     x21, x22, [sp, 32]
@@ -663,6 +829,23 @@ FUNCTION(caml_reraise_exn)
         CFI_ENDPROC
         END_FUNCTION(caml_reraise_exn)
 
+#if defined(WITH_THREAD_SANITIZER)
+/* When TSan support is enabled, this routine should be called just before
+   raising an exception. It calls __tsan_func_exit for every OCaml frame about
+   to be exited due to the exception.
+   Takes no arguments, clobbers x0, x1, x2 and potentially all
+   caller-saved registers of the C calling convention. */
+FUNCTION(caml_tsan_exit_on_raise_asm)
+        CFI_STARTPROC
+        mov     x0, x30        /* arg1: pc of raise */
+        mov     x1, sp         /* arg2: sp of raise */
+        mov     x2, TRAP_PTR   /* arg3: sp of handler */
+        TSAN_C_CALL G(caml_tsan_exit_on_raise)
+        ret
+        CFI_ENDPROC
+        END_FUNCTION(caml_tsan_exit_on_raise_asm)
+#endif
+
 /* Raise an exception from C */
 
 FUNCTION(caml_raise_exception)
@@ -678,6 +861,22 @@ FUNCTION(caml_raise_exception)
         ldr     TMP, Caml_state(current_stack)
         ldr     TMP, Stack_sp(TMP)
         mov     sp, TMP
+#if defined(WITH_THREAD_SANITIZER)
+        str     x0, [sp, -16]! /* preserve exception bucket */
+        CFI_ADJUST(16)
+    /* Call __tsan_func_exit for every OCaml stack frame exited due to the
+       exception */
+        mov     x1, TMP
+        ldr     x0, [x1, 8]    /* arg1: pc of raise */
+        /* This stack address adjustment is required to compensate the
+           saving of x29 and x30 in SWITCH_OCAML_STACKS, which causes
+           Stack_sp() to be 16 bytes lower than expected. */
+        add     x1, x1, 16     /* arg2: sp of raise */
+        mov     x2, TRAP_PTR   /* arg3: sp of handler */
+        TSAN_C_CALL G(caml_tsan_exit_on_raise)
+        ldr     x0, [sp], 16
+        CFI_ADJUST(-16)
+#endif
     /* Restore frame and link on return to OCaml */
         ldp     x29, x30, [sp], 16
         b       G(caml_raise_exn)
@@ -688,6 +887,19 @@ FUNCTION(caml_raise_exception)
 
 FUNCTION(caml_callback_asm)
         CFI_STARTPROC
+#if defined(WITH_THREAD_SANITIZER)
+    /* Save non-callee-saved registers x0, x1, x2 and x30 before C call */
+        stp     x0, x1, [sp, -16]!
+        CFI_ADJUST(16)
+        stp     x2, x30, [sp, -16]!
+        CFI_ADJUST(16)
+        mov     x0, x30 /* return address */
+        bl      G(__tsan_func_entry)
+        ldp     x2, x30, [sp], 16
+        CFI_ADJUST(-16)
+        ldp     x0, x1, [sp], 16
+        CFI_ADJUST(-16)
+#endif
     /* Initial shuffling of arguments */
     /* (x0 = Caml_state, x1 = closure, [x2] = first arg) */
         mov     TMP, x0
@@ -700,6 +912,19 @@ FUNCTION(caml_callback_asm)
 
 FUNCTION(caml_callback2_asm)
         CFI_STARTPROC
+#if defined(WITH_THREAD_SANITIZER)
+    /* Save non-callee-saved registers x0, x1, x2 and x30 before C call */
+        stp     x0, x1, [sp, -16]!
+        CFI_ADJUST(16)
+        stp     x2, x30, [sp, -16]!
+        CFI_ADJUST(16)
+        mov     x0, x30 /* return address */
+        bl      G(__tsan_func_entry)
+        ldp     x2, x30, [sp], 16
+        CFI_ADJUST(-16)
+        ldp     x0, x1, [sp], 16
+        CFI_ADJUST(-16)
+#endif
     /* Initial shuffling of arguments */
     /* (x0 = Caml_state, x1 = closure, [x2] = arg1, [x2,8] = arg2) */
         mov     TMP, x0
@@ -713,6 +938,19 @@ FUNCTION(caml_callback2_asm)
 
 FUNCTION(caml_callback3_asm)
         CFI_STARTPROC
+#if defined(WITH_THREAD_SANITIZER)
+    /* Save non-callee-saved registers x0, x1, x2 and x30 before C call */
+        stp     x0, x1, [sp, -16]!
+        CFI_ADJUST(16)
+        stp     x2, x30, [sp, -16]!
+        CFI_ADJUST(16)
+        mov     x0, x30 /* return address */
+        bl      G(__tsan_func_entry)
+        ldp     x2, x30, [sp], 16
+        CFI_ADJUST(-16)
+        ldp     x0, x1, [sp], 16
+        CFI_ADJUST(-16)
+#endif
     /* Initial shuffling of arguments */
     /* (x0 = Caml_state, x1 = closure, [x2] = arg1, [x2,8] = arg2,
         [x2,16] = arg3) */
@@ -746,6 +984,7 @@ FUNCTION(caml_callback3_asm)
         ldr     TRAP_PTR, Stack_exception(\new_stack)
     /* Restore frame pointer and return address for new_stack */
         ldp     x29, x30, [sp], 16
+        CFI_ADJUST(-16)
 .endm
 
 
@@ -768,10 +1007,34 @@ L(do_perform):
         x1: continuation
         x2: old_stack
         x3: last_fiber */
-
+#if defined(WITH_THREAD_SANITIZER)
+    /* Signal to TSan all stack frames exited by the perform. */
+        TSAN_SAVE_CALLER_REGS
+        mov     x0, x30 /* arg 1: pc of perform */
+        mov     x1, sp  /* arg 2: sp of perform */
+        TSAN_C_CALL G(caml_tsan_exit_on_perform)
+        TSAN_RESTORE_CALLER_REGS
+#endif
         ldr     x9, Stack_handler(x2)  /* x9 := old stack -> handler */
         ldr     x10, Handler_parent(x9) /* x10 := parent stack */
         cbz     x10, 1f
+#if defined(WITH_THREAD_SANITIZER)
+    /* Save non-callee-saved registers x0, x1, x2, x3, x9 and x10 */
+        stp     x0, x1, [sp, -16]!
+        CFI_ADJUST(16)
+        stp     x2, x3, [sp, -16]!
+        CFI_ADJUST(16)
+        stp     x9, x10, [sp, -16]!
+        CFI_ADJUST(16)
+    /* Match the TSan-enter made from caml_runstack */
+        TSAN_EXIT_FUNCTION
+        ldp     x9, x10, [sp], 16
+        CFI_ADJUST(-16)
+        ldp     x2, x3, [sp], 16
+        CFI_ADJUST(-16)
+        ldp     x0, x1, [sp], 16
+        CFI_ADJUST(-16)
+#endif
         SWITCH_OCAML_STACKS x2, x10
     /*  we have to null the Handler_parent after the switch because
         the Handler_parent is needed to unwind the stack for backtraces */
@@ -788,6 +1051,20 @@ L(do_perform):
         ldr     x9, Caml_state(current_stack)
         SWITCH_OCAML_STACKS x9, x10
     /*  No parent stack. Raise Effect.Unhandled. */
+#if defined(WITH_THREAD_SANITIZER)
+        /* We must let the TSan runtime know that we switched back to the
+           original performer stack. For that, we perform the necessary calls
+           to __tsan_func_entry via caml_tsan_entry_on_resume.
+           Note that from TSan's point of view, we just exited all stack
+           frames, including those of the main fiber. This is ok, because we
+           re-enter them immediately via caml_tsan_entry_on_resume below. */
+        TSAN_SAVE_CALLER_REGS
+        mov     x0, x30 /* arg 1: pc of perform */
+        mov     x1, sp  /* arg 2: sp of perform */
+        mov     x2, x10 /* arg 3: performer stack */
+        TSAN_C_CALL G(caml_tsan_entry_on_resume)
+        TSAN_RESTORE_CALLER_REGS
+#endif
         ADDRGLOBAL(ADDITIONAL_ARG, caml_raise_unhandled_effect)
         b       G(caml_c_call)
         CFI_ENDPROC
@@ -816,6 +1093,34 @@ CFI_STARTPROC
         ldr     x4, [x1]  /* code pointer */
     /* Check if stack null, then already used */
         cbz     x0, 1f
+#if defined(WITH_THREAD_SANITIZER)
+    /* Save non-callee-saved registers x0, x1, x2, x3 and x4 */
+        stp     x0, x1, [sp, -16]!
+        CFI_ADJUST(16)
+        stp     x2, x3, [sp, -16]!
+        CFI_ADJUST(16)
+        str     x4, [sp, -16]!
+        CFI_ADJUST(16)
+    /* Necessary to include the caller of caml_resume in the TSan backtrace */
+        TSAN_ENTER_FUNCTION
+        ldr     x4, [sp], 16
+        CFI_ADJUST(-16)
+        ldp     x2, x3, [sp], 16
+        CFI_ADJUST(-16)
+        ldp     x0, x1, [sp], 16
+        CFI_ADJUST(-16)
+        TSAN_SAVE_CALLER_REGS
+    /* Signal to TSan all stack frames exited by the perform. */
+        mov     x2, x0           /* arg 3: fiber */
+        ldr     x1, Stack_sp(x0)
+        ldr     x0, [x1, 8]      /* arg 1: pc of perform */
+        /* This stack address adjustment is required to compensate the
+           saving of x29 and x30 in SWITCH_OCAML_STACKS, which causes
+           Stack_sp() to be 16 bytes lower than expected. */
+        add     x1, x1, 16       /* arg 2: sp at perform */
+        TSAN_C_CALL G(caml_tsan_entry_on_resume)
+        TSAN_RESTORE_CALLER_REGS
+#endif
     /* Add current stack to the end */
         sub     x3, x3, 1 /* x3 = Ptr_val(x3) */
         ldr     x8, Stack_handler(x3)
@@ -833,6 +1138,19 @@ CFI_STARTPROC
    return the value or invoke exception handler */
 FUNCTION(caml_runstack)
 CFI_STARTPROC
+#if defined(WITH_THREAD_SANITIZER)
+    /* Save non-callee-saved registers x0, x1 and x2 */
+        stp     x0, x1, [sp, -16]!
+        CFI_ADJUST(16)
+        str     x2, [sp, -16]!
+        CFI_ADJUST(16)
+    /* Necessary to include the caller of caml_runstack in the TSan backtrace */
+        TSAN_ENTER_FUNCTION
+        ldr     x2, [sp], 16
+        CFI_ADJUST(-16)
+        ldp     x0, x1, [sp], 16
+        CFI_ADJUST(-16)
+#endif
     /*  x0: fiber
         x1: fun
         x2: arg */
@@ -898,11 +1216,14 @@ L(frame_runstack):
         ldr     TMP, Caml_state(c_stack)
         mov     sp, TMP
         bl      G(caml_free_stack)
-    /* switch directly to parent stack with correct return */
-        mov     x0, x20
-        mov     x1, x19
+    /* switch directly to parent stack */
         mov     sp, x21
         CFI_RESTORE_STATE
+    /* Signal to TSan that we exit caml_runstack (no registers to save here) */
+        TSAN_EXIT_FUNCTION
+    /* pick correct return value */
+        mov     x0, x20
+        mov     x1, x19
         ldr     TMP, [x19]  /* code pointer */
     /* Invoke handle_value (or handle_exn) */
         ldp     x29, x30, [sp], 16
